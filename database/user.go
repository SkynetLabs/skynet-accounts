package database

import (
	"context"
	"strconv"
	"sync"
	"sync/atomic"
	"time"

	"github.com/NebulousLabs/skynet-accounts/build"

	"gitlab.com/NebulousLabs/errors"
	"go.mongodb.org/mongo-driver/bson"
	"go.mongodb.org/mongo-driver/bson/primitive"
	"go.mongodb.org/mongo-driver/mongo"
	"go.mongodb.org/mongo-driver/mongo/options"
)

const (
	// TierReserved reserved
	TierReserved = iota
	// TierFree free
	TierFree
	// TierPremium5 5
	TierPremium5
	// TierPremium20 20
	TierPremium20
	// TierPremium80 80
	TierPremium80

	// KiB kilobyte
	KiB = 1024
	// MiB megabyte
	MiB = 1024 * KiB

	// PriceBandwidthRegistryWrite the bandwidth cost of a single registry write
	PriceBandwidthRegistryWrite = 5 * MiB
	// PriceBandwidthRegistryRead the bandwidth cost of a single registry read
	PriceBandwidthRegistryRead = MiB

	// PriceBandwidthUploadBase is the baseline bandwidth price for each upload.
	// This is the cost of uploading the base sector.
	PriceBandwidthUploadBase = 40 * MiB
	// PriceBandwidthUploadIncrement is the bandwidth price per 40MB beyond
	// the base sector (beyond the first 4MB). Rounded up.
	PriceBandwidthUploadIncrement = 120 * MiB
	// PriceBandwidthDownloadBase is the baseline bandwidth price for each Download.
	PriceBandwidthDownloadBase = 200 * KiB
	// PriceBandwidthDownloadIncrement is the bandwidth price per 64B. Rounded up.
	PriceBandwidthDownloadIncrement = 64

	// PriceStorageUploadBase is the baseline storage price for each upload.
	// This is the cost of uploading the base sector.
	PriceStorageUploadBase = 4 * MiB
	// PriceStorageUploadIncrement is the storage price for each 40MB beyond
	// the base sector (beyond the first 4MB). Rounded up.
	PriceStorageUploadIncrement = 40 * MiB
)

type (
	// User represents a Skynet user.
	User struct {
		// ID is a hexadecimal string representation of the MongoDB id assigned
		// to this user object. It is auto-generated by Mongo on insert.
		ID              primitive.ObjectID `bson:"_id,omitempty" json:"-"`
		Sub             string             `bson:"sub" json:"sub"`
		Tier            int                `bson:"tier" json:"tier"`
		StorageUsed     int64              `bson:"storage_used" json:"storageUsed"`
		SubscribedUntil time.Time          `bson:"subscribed_until" json:"subscribedUntil"`
	}
	// UserDetails builds on top of User and provides additional information,
	// typically more expensive to fetch than a single DB query.
	UserDetails struct {
		User
		BandwidthUsed int64 `bson:"-" json:"bandwidthUsed"`
	}
)

// UserBySub returns the user with the given sub. If `create` is `true` it will
// create the user if it doesn't exist. The sub is the Kratos id of that user.
func (db *DB) UserBySub(ctx context.Context, sub string, create bool) (*User, error) {
	users, err := db.managedUsersByField(ctx, "sub", sub)
	if create && errors.Contains(err, ErrUserNotFound) {
		return db.UserCreate(ctx, sub, TierFree)
	}
	if err != nil {
		return nil, err
	}
	return users[0], nil
}

// UserByID finds a user by their ID.
func (db *DB) UserByID(ctx context.Context, id primitive.ObjectID) (*User, error) {
	filter := bson.D{{"_id", id}}
	c, err := db.staticUsers.Find(ctx, filter)
	if err != nil {
		return nil, errors.AddContext(err, "failed to Find")
	}
	defer func() { _ = c.Close(ctx) }()
	// Get the first result.
	if ok := c.Next(ctx); !ok {
		return nil, ErrUserNotFound
	}
	// Ensure there are no more results.
	if ok := c.Next(ctx); ok {
		build.Critical("more than one user found for id", id)
	}
	var u User
	err = c.Decode(&u)
	if err != nil {
		return nil, errors.AddContext(err, "failed to parse value from DB")
	}
	return &u, nil
}

// UserCreate creates a new user in the DB.
func (db *DB) UserCreate(ctx context.Context, sub string, tier int) (*User, error) {
	// Check for an existing user with this sub.
	users, err := db.managedUsersByField(ctx, "sub", sub)
	if err != nil && !errors.Contains(err, ErrUserNotFound) {
		return nil, errors.AddContext(err, "failed to query DB")
	}
	if len(users) > 0 {
		return nil, ErrUserAlreadyExists
	}
	u := &User{
		ID:   primitive.ObjectID{},
		Sub:  sub,
		Tier: tier,
	}
	// Insert the user.
	fields, err := bson.Marshal(u)
	if err != nil {
		return nil, err
	}
	ir, err := db.staticUsers.InsertOne(ctx, fields)
	if err != nil {
		return nil, errors.AddContext(err, "failed to Insert")
	}
	u.ID = ir.InsertedID.(primitive.ObjectID)
	return u, nil
}

// UserDetails returns the full user profile information.
func (db *DB) UserDetails(ctx context.Context, user *User) (*UserDetails, error) {
	// Refresh the user from the DB.
	u, err := db.UserByID(ctx, user.ID)
	if err != nil {
		return nil, err
	}
	// Fetch the details.
	bandwidthUsed, err := db.userBandwidth(ctx, user.ID)
	if err != nil {
		db.staticLogger.Debugf("Failed to fetch bandwidth used for user (%v): %v", user.Sub, err)
		return nil, err
	}
	return &UserDetails{
		User:          *u,
		BandwidthUsed: bandwidthUsed,
	}, err
}

// UserDelete deletes a user by their ID.
func (db *DB) UserDelete(ctx context.Context, u *User) error {
	if u.ID.IsZero() {
		return errors.AddContext(ErrUserNotFound, "user struct not fully initialised")
	}
	filter := bson.D{{"_id", u.ID}}
	dr, err := db.staticUsers.DeleteOne(ctx, filter)
	if err != nil {
		return errors.AddContext(err, "failed to Delete")
	}
	if dr.DeletedCount == 0 {
		return ErrUserNotFound
	}
	return nil
}

// UserUpdate changes the user's data in the DB.
// It never changes the id or sub of the user.
func (db *DB) UserUpdate(ctx context.Context, u *User) error {
	// Update the user.
	filter := bson.M{"_id": u.ID}
	update := bson.M{"$set": bson.M{
		"tier": u.Tier,
	}}
	opts := options.Update().SetUpsert(true)
	_, err := db.staticUsers.UpdateOne(ctx, filter, update, opts)
	if err != nil {
		return errors.AddContext(err, "failed to update")
	}
	return nil
}

// UserUpdateUsedStorage changes the user's used storage respective to the size
// of the upload.
func (db *DB) UserUpdateUsedStorage(ctx context.Context, id primitive.ObjectID, uploadSize int64) error {
	if uploadSize <= 0 {
		return errors.New("invalid upload size, it needs to be positive, got: " + strconv.Itoa(int(uploadSize)))
	}
	filter := bson.M{"_id": id}
	update := bson.M{"$inc": bson.M{
		"storage_used": StorageUsed(uint64(uploadSize)),
	}}
	_, err := db.staticUsers.UpdateOne(ctx, filter, update)
	return err
}

// managedUsersByField finds all users that have a given field value.
// The calling method is responsible for the validation of the value.
func (db *DB) managedUsersByField(ctx context.Context, fieldName, fieldValue string) ([]*User, error) {
	filter := bson.D{{fieldName, fieldValue}}
	c, err := db.staticUsers.Find(ctx, filter)
	if err != nil {
		return nil, errors.AddContext(err, "failed to find user")
	}
	defer func() { _ = c.Close(ctx) }()

	var users []*User
	for c.Next(ctx) {
		var u User
		if err = c.Decode(&u); err != nil {
			return nil, errors.AddContext(err, "failed to parse value from DB")
		}
		users = append(users, &u)
	}
	if len(users) == 0 {
		return users, ErrUserNotFound
	}
	return users, nil
}

// userBandwidth reports the total bandwidth used by the user.
func (db *DB) userBandwidth(ctx context.Context, id primitive.ObjectID) (int64, error) {
	var bandwidthAtomic int64
	var errs []error
	var errsMux sync.Mutex
	regErr := func(msg string, e error) {
		db.staticLogger.Info(msg, e)
		errsMux.Lock()
		errs = append(errs, e)
		errsMux.Unlock()
	}
	monthStart, err := db.monthStart(ctx, id)
	if err != nil {
		return 0, errors.AddContext(err, "failed to calculate the start of month for user")
	}

	var wg sync.WaitGroup
	wg.Add(1)
	go func() {
		defer wg.Done()
		bw, err := db.userUploadBandwidth(ctx, id, monthStart)
		if err != nil {
			regErr("Failed to get user's upload bandwidth used:", err)
			return
		}
		db.staticLogger.Tracef("User %s upload bandwidth: %v", id.Hex(), bw)
		atomic.AddInt64(&bandwidthAtomic, bw)
	}()
	wg.Add(1)
	go func() {
		defer wg.Done()
		bw, err := db.userDownloadBandwidth(ctx, id, monthStart)
		if err != nil {
			regErr("Failed to get user's download bandwidth used:", err)
			return
		}
		db.staticLogger.Tracef("User %s download bandwidth: %v", id.Hex(), bw)
		atomic.AddInt64(&bandwidthAtomic, bw)
	}()
	wg.Add(1)
	go func() {
		defer wg.Done()
		bw, err := db.userRegistryWriteBandwidth(ctx, id, monthStart)
		if err != nil {
			regErr("Failed to get user's registry write bandwidth used:", err)
			return
		}
		db.staticLogger.Tracef("User %s registry write bandwidth: %v", id.Hex(), bw)
		atomic.AddInt64(&bandwidthAtomic, bw)
	}()
	wg.Add(1)
	go func() {
		defer wg.Done()
		bw, err := db.userRegistryReadBandwidth(ctx, id, monthStart)
		if err != nil {
			regErr("Failed to get user's registry read bandwidth used:", err)
			return
		}
		db.staticLogger.Tracef("User %s registry read bandwidth: %v", id.Hex(), bw)
		atomic.AddInt64(&bandwidthAtomic, bw)
	}()

	wg.Wait()
	if len(errs) > 0 {
		return 0, errors.Compose(errs...)
	}
	return bandwidthAtomic, nil
}

// userUploadBandwidth reports the upload bandwidth used by the user. It uses
// the total size of the uploaded skyfiles as basis.
func (db *DB) userUploadBandwidth(ctx context.Context, id primitive.ObjectID, monthStart time.Time) (int64, error) {
	matchStage := bson.D{{"$match", bson.D{
		{"user_id", id},
		{"timestamp", bson.D{{"$gt", monthStart}}},
	}}}
	lookupStage := bson.D{
		{"$lookup", bson.D{
			{"from", "skylinks"},
			{"localField", "skylink_id"},
			{"foreignField", "_id"},
			{"as", "skylink_data"},
		}},
	}
	replaceStage := bson.D{
		{"$replaceRoot", bson.D{
			{"newRoot", bson.D{
				{"$mergeObjects", bson.A{
					bson.D{{"$arrayElemAt", bson.A{"$skylink_data", 0}}}, "$$ROOT"},
				},
			}},
		}},
	}
	// These are the fields we don't need.
	projectStage := bson.D{{"$project", bson.D{
		{"_id", 0},
		{"user_id", 0},
		{"skylink", 0},
		{"skylink_data", 0},
		{"name", 0},
		{"skylink_id", 0},
		{"timestamp", 0},
	}}}

	pipeline := mongo.Pipeline{matchStage, lookupStage, replaceStage, projectStage}
	c, err := db.staticUploads.Aggregate(ctx, pipeline)
	if err != nil {
		return 0, err
	}
	defer func() { _ = c.Close(ctx) }()
	var bandwidth int64
	// We need this struct, so we can safely decode both int32 and int64.
	result := struct {
		Size uint64 `bson:"size"`
	}{}
	for c.Next(ctx) {
		if err = c.Decode(&result); err != nil {
			return 0, errors.AddContext(err, "failed to decode DB data")
		}
		bandwidth += PriceBandwidthUploadBase + int64(numChunks(result.Size))*PriceBandwidthUploadIncrement
	}
	return bandwidth, nil
}

// userDownloadBandwidth reports the download bandwidth used by the user. It
// uses the cumulative downloaded amount, noted with each download record. Those
// numbers account for the actual bandwidth used, as reported by nginx.
func (db *DB) userDownloadBandwidth(ctx context.Context, id primitive.ObjectID, monthStart time.Time) (int64, error) {
	matchStage := bson.D{{"$match", bson.D{
		{"user_id", id},
		{"timestamp", bson.D{{"$gt", monthStart}}},
	}}}
	lookupStage := bson.D{
		{"$lookup", bson.D{
			{"from", "skylinks"},
			{"localField", "skylink_id"}, // field in the downloads collection
			{"foreignField", "_id"},      // field in the skylinks collection
			{"as", "fromSkylinks"},
		}},
	}
	replaceStage := bson.D{
		{"$replaceRoot", bson.D{
			{"newRoot", bson.D{
				{"$mergeObjects", bson.A{
					bson.D{{"$arrayElemAt", bson.A{"$fromSkylinks", 0}}}, "$$ROOT"},
				},
			}},
		}},
	}
	// This stage checks if the download has a non-zero `bytes` field and if so,
	// it takes it as the download's size. Otherwise it reports the full
	// skylink's size as download's size.
	projectStage := bson.D{{"$project", bson.D{
		{"size", bson.D{
			{"$cond", bson.A{
				bson.D{{"$gt", bson.A{"$bytes", 0}}}, // if
				"$bytes",                             // then
				"$size",                              // else
			}},
		}},
	}}}

	pipeline := mongo.Pipeline{matchStage, lookupStage, replaceStage, projectStage}
	c, err := db.staticDownloads.Aggregate(ctx, pipeline)
	if err != nil {
		return 0, errors.AddContext(err, "DB query failed")
	}
	defer func() { _ = c.Close(ctx) }()
	var bandwidth int64
	// We need this struct, so we can safely decode both int32 and int64.
	result := struct {
		Size uint64 `bson:"size"`
	}{}
	for c.Next(ctx) {
		if err = c.Decode(&result); err != nil {
			return 0, errors.AddContext(err, "failed to decode DB data")
		}
		var incomplete uint64
		if result.Size%64 > 0 {
			incomplete = 1
		}
		bandwidth += PriceBandwidthDownloadBase + int64(result.Size/64+incomplete)*PriceBandwidthDownloadIncrement
	}
	return bandwidth, nil
}

// userRegistryWriteBandwidth reports the bandwidth used by the user's registry
// writes.
func (db *DB) userRegistryWriteBandwidth(ctx context.Context, userId primitive.ObjectID, monthStart time.Time) (int64, error) {
	matchStage := bson.D{{"$match", bson.D{
		{"user_id", userId},
		{"timestamp", bson.D{{"$gt", monthStart}}},
	}}}
	writes, err := count(ctx, db.staticRegistryWrites, matchStage)
	if err != nil {
		return 0, errors.AddContext(err, "failed to fetch registry write bandwidth")
	}
	return writes * PriceBandwidthRegistryWrite, nil
}

// userRegistryReadBandwidth reports the bandwidth used by the user's registry
// reads.
func (db *DB) userRegistryReadBandwidth(ctx context.Context, userId primitive.ObjectID, monthStart time.Time) (int64, error) {
	matchStage := bson.D{{"$match", bson.D{
		{"user_id", userId},
		{"timestamp", bson.D{{"$gt", monthStart}}},
	}}}
	reads, err := count(ctx, db.staticRegistryReads, matchStage)
	if err != nil {
		return 0, errors.AddContext(err, "failed to fetch registry read bandwidth")
	}
	return reads * PriceBandwidthRegistryRead, nil
}

// monthStart returns the start of the user's subscription month. Users get
// their bandwidth quota reset at the start of the month.
func (db *DB) monthStart(ctx context.Context, userId primitive.ObjectID) (time.Time, error) {
	user, err := db.UserByID(ctx, userId)
	if err != nil {
		return time.Time{}, errors.AddContext(err, "failed to fetch user")
	}
	now := time.Now().UTC()
	daysDelta := now.Day() - user.SubscribedUntil.Day()
	d := now.AddDate(0, 0, -1*daysDelta)
	if daysDelta <= 0 {
		d = now.AddDate(0, -1, daysDelta)
	}
	monthStart := time.Date(d.Year(), d.Month(), d.Day(), 0, 0, 0, 0, time.UTC)
	return monthStart, nil
}

// numChunks returns the number of 40MB chunks a file of this size uses, beyond
// the 4MB in the base sector.
func numChunks(size uint64) uint64 {
	if size <= 4*MiB {
		return 0
	}
	chunksBeyondBase := (size - 4*MiB) / (40 * MiB)
	if (size-4*MiB)%(40*MiB) > 0 {
		chunksBeyondBase++
	}
	return chunksBeyondBase
}

// StorageUsed calculates how much storage an upload with a given size actually
// uses.
func StorageUsed(uploadSize uint64) uint64 {
	return PriceStorageUploadBase + numChunks(uploadSize)*PriceStorageUploadIncrement
}
